#!/usr/bin/env python3
"""
Extract user messages from Cursor chat markdown files.
This script efficiently processes all .md files in the chats folder and extracts only user messages.
"""

import os
import re
from pathlib import Path
from typing import List, Tuple

def extract_user_messages_from_file(file_path: Path) -> List[str]:
    """
    Extract user messages from a single markdown file.
    
    Args:
        file_path: Path to the markdown file
        
    Returns:
        List of user messages
    """
    user_messages = []
    
    try:
        with open(file_path, 'r', encoding='utf-8') as file:
            content = file.read()
            
        # Split content by the separator pattern
        # Pattern matches: "---" followed by optional whitespace and newline
        sections = re.split(r'---\s*\n', content)
        
        for section in sections:
            section = section.strip()
            if not section:
                continue
                
            # Check if this section starts with "**User**"
            if section.startswith('**User**'):
                # Extract the message content after "**User**"
                message_start = section.find('**User**') + len('**User**')
                message_content = section[message_start:].strip()
                
                # Clean up the message (remove leading/trailing whitespace and newlines)
                message_content = re.sub(r'^\s*\n+', '', message_content)
                message_content = re.sub(r'\n+\s*$', '', message_content)
                
                if message_content:
                    user_messages.append(message_content)
                    
    except Exception as e:
        print(f"Error processing {file_path}: {e}")
        
    return user_messages

def process_all_chat_files(chats_dir: str = "chats") -> List[Tuple[str, List[str]]]:
    """
    Process all markdown files in the chats directory.
    
    Args:
        chats_dir: Path to the chats directory
        
    Returns:
        List of tuples containing (filename, user_messages)
    """
    chats_path = Path(chats_dir)
    
    if not chats_path.exists():
        print(f"Directory {chats_dir} does not exist")
        return []
    
    results = []
    
    # Find all .md files in the chats directory
    md_files = list(chats_path.glob("*.md"))
    
    if not md_files:
        print(f"No .md files found in {chats_dir}")
        return []
    
    print(f"Found {len(md_files)} markdown files to process:")
    for md_file in md_files:
        print(f"  - {md_file.name}")
    
    print("\nProcessing files...")
    
    for md_file in md_files:
        print(f"Processing {md_file.name}...")
        user_messages = extract_user_messages_from_file(md_file)
        results.append((md_file.name, user_messages))
        print(f"  Extracted {len(user_messages)} user messages")
    
    return results

def save_results(results: List[Tuple[str, List[str]]], output_file: str = "extracted_user_messages.md"):
    """
    Save the extracted user messages to a markdown file.
    
    Args:
        results: List of (filename, user_messages) tuples
        output_file: Output file path
    """
    # Collect all messages and remove duplicates
    all_messages = set()
    message_sources = {}  # Track which files each message appears in
    
    for filename, messages in results:
        for message in messages:
            # Normalize message for deduplication (remove extra whitespace)
            normalized_message = re.sub(r'\s+', ' ', message.strip())
            if normalized_message:
                all_messages.add(normalized_message)
                if normalized_message not in message_sources:
                    message_sources[normalized_message] = []
                message_sources[normalized_message].append(filename)
    
    # Sort messages alphabetically
    sorted_messages = sorted(all_messages)
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("# Extracted User Messages from Cursor Chats\n\n")
        f.write("_Generated by extract_user_messages.py_\n")
        f.write("_Sorted and deduplicated_\n\n")
        
        f.write(f"## Summary\n\n")
        f.write(f"Total files processed: {len(results)}\n")
        f.write(f"Total unique messages: {len(sorted_messages)}\n\n")
        
        f.write("## All Unique Messages (Sorted)\n\n")
        
        for i, message in enumerate(sorted_messages, 1):
            f.write(f"### Message {i}\n\n")
            f.write(f"{message}\n\n")
            
            # Show which files this message appears in
            sources = message_sources[message]
            if len(sources) > 1:
                f.write(f"**Appears in:** {', '.join(sources)}\n\n")
            else:
                f.write(f"**Appears in:** {sources[0]}\n\n")
            
            f.write("---\n\n")
    
    print(f"\nResults saved to {output_file}")
    print(f"Total unique messages: {len(sorted_messages)}")
    
    # Also save original file-by-file breakdown
    original_output_file = "extracted_user_messages_by_file.md"
    with open(original_output_file, 'w', encoding='utf-8') as f:
        f.write("# Extracted User Messages by File\n\n")
        f.write("_Generated by extract_user_messages.py_\n\n")
        
        total_messages = 0
        
        for filename, messages in results:
            if messages:
                f.write(f"## {filename}\n\n")
                total_messages += len(messages)
                
                for i, message in enumerate(messages, 1):
                    f.write(f"### Message {i}\n\n")
                    f.write(f"{message}\n\n")
                    f.write("---\n\n")
        
        f.write(f"\n## Summary\n\n")
        f.write(f"Total files processed: {len(results)}\n")
        f.write(f"Total user messages extracted: {total_messages}\n")
    
    print(f"Original file-by-file breakdown saved to {original_output_file}")
    print(f"Total messages extracted (before deduplication): {total_messages}")

def main():
    """Main function to run the extraction process."""
    print("Extracting user messages from Cursor chat files...\n")
    
    # Process all chat files
    results = process_all_chat_files()
    
    if results:
        # Save results to file
        save_results(results)
        
        # Also print summary to console
        print("\n" + "="*50)
        print("SUMMARY")
        print("="*50)
        
        total_messages = 0
        for filename, messages in results:
            print(f"{filename}: {len(messages)} messages")
            total_messages += len(messages)
        
        print(f"\nTotal messages across all files: {total_messages}")
        
        # Calculate unique messages
        all_messages = set()
        for filename, messages in results:
            for message in messages:
                normalized_message = re.sub(r'\s+', ' ', message.strip())
                if normalized_message:
                    all_messages.add(normalized_message)
        
        unique_count = len(all_messages)
        duplicate_count = total_messages - unique_count
        
        print(f"Unique messages: {unique_count}")
        print(f"Duplicate messages removed: {duplicate_count}")
        print(f"Deduplication rate: {(duplicate_count/total_messages*100):.1f}%" if total_messages > 0 else "Deduplication rate: 0%")
    else:
        print("No results to save.")

if __name__ == "__main__":
    main() 